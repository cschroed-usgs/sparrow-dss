<?xml version="1.0" ?>
<ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:noNamespaceSchemaLocation="ehcache.xsd">

	<!--
	Note:  For caches with factories (all of them for this project), 
	you must create the factory-cache association in the
	gov.usgswim.sparrow.LifecycleListener class.
	
	-->

	<!--
		CacheManager Configuration
		==========================
		An ehcache.xml corresponds to a single CacheManager.
		
		See instructions below or the ehcache schema (ehcache.xsd) on how to configure.
		
		DiskStore configuration
		=======================
		
		Sets the path to the directory where cache files are created.
		
		If the path is a Java System Property it is replaced by its value in the
		running VM.
		
		The following properties are translated:
		* user.home - User's home directory
		* user.dir - User's current working directory
		* java.io.tmpdir - Default temp file path
		
		Subdirectories can be specified below the property e.g. java.io.tmpdir/one
	-->
	<!-- DISTRIBUTED CACHE CONFIGURATION:  Quoted from bottom of http://ehcache.org/documentation/distributed_caching.html
	
			Use of Time To Idle

			Time To Idle is inconsistent with distributed caching. Time-to-idle makes 
			some entries live longer on some nodes than in others because of cache 
			usage patterns. However, the cache entry "last touched" timestamp is 
			not replicated across the distributed cache.

			Do not use Time To Idle with distributed caching, unless you do not 
			care about inconsistent data across nodes. 
	 -->
	<!-- DISTRIBUTED CACHE CONFIGURATION:  See SharedApplication.putPredictionContext(), line 176
	
		Typical Sparrow configuration value for:
		cacheManagerPeerProviderFactory.class=
			"net.sf.ehcache.distribution.RMICacheManagerPeerProviderFactory"
				||
			"gov.usgswim.sparrow.clustering.DummyCacheManagerPeerProviderFactory"
		
		
		cacheManagerPeerProviderFactory.properties=
			"peerDiscovery=manual,rmiUrls=//130.11.165.157:1099/PredictContext|//130.11.165.157:1099/AdjustmentGroups|//130.11.165.157:1099/Analyses|//130.11.165.157:1099/TerminalReaches|//130.11.165.157:1099/AreaOfInterest"
	 			||
	 		""
	 		
	 	cacheManagerPeerListenerFactory.class=
			"net.sf.ehcache.distribution.RMICacheManagerPeerListenerFactory"
				||
			"gov.usgswim.sparrow.clustering.DummyCacheManagerPeerListenerFactory"
			
			
		cacheManagerPeerListenerFactory.properties=
			"port=1099,socketTimeoutMillis=2000"
				||
			""
	 	
	 	For clustered operation using RMI syncing, choose the first value option.
	 	For local non-clustered development operation, choose the second set of value options.
	 	
	 	For each of the above configuration choices, this will be set in a JNDI 
	 	property in order to maintain WAR invariance. 
	 		(override = true to allow WAR to override JNDI in special cases. See )
	 		For example: 
	 		<Environment 
	 			 name="cacheManagerPeerProviderFactory.class" 
	 			 value="cida.usgs.gov"
        		 type="java.lang.String"
        		 override="true"
        	/>
        
        The places in the ehcache.xml below would then be filled by something similar
			<cacheManagerPeerProviderFactory
 				class="${cacheManagerPeerProviderFactory.class}"
				properties="${cacheManagerPeerProviderFactory.properties}"/>
 			<cacheManagerPeerListenerFactory
				class="${cacheManagerPeerListenerFactory.class}"
				properties="${cacheManagerPeerListenerFactory.properties}"/>
		
		For an example configuration of javadev, see SparrowJNDI.txt in src/main/resources
	 -->
	 <!-- DISTRIBUTED CACHE CONFIGURATION ${cacheManagerPeerProviderFactory} /END -->
	 	
	 <!-- DISTRIBUTED CACHE CONFIGURATION  ${cacheManagerPeerListenerFactory} /END -->
	
	<!--		
	<diskStore path="java.io.tmpdir/ehcache_diskstore" />
	-->

	<!--
		Cache configuration
		===================
		
		The following attributes are required.
		
		name:
		Sets the name of the cache. This is used to identify the cache. It must be unique.
		
		maxElementsInMemory:
		Sets the maximum number of objects that will be created in memory
		
		maxElementsOnDisk:
		Sets the maximum number of objects that will be maintained in the DiskStore
		The default value is zero, meaning unlimited.
		
		eternal:
		Sets whether elements are eternal. If eternal,  timeouts are ignored and the
		element is never expired.
		
		overflowToDisk:
		Sets whether elements can overflow to disk when the memory store
		has reached the maxInMemory limit.
		
		The following attributes and elements are optional.
		
		timeToIdleSeconds:
		Sets the time to idle for an element before it expires.
		i.e. The maximum amount of time between accesses before an element expires
		Is only used if the element is not eternal.
		Optional attribute. A value of 0 means that an Element can idle for infinity.
		The default value is 0.
		
		timeToLiveSeconds:
		Sets the time to live for an element before it expires.
		i.e. The maximum time between creation time and when an element expires.
		Is only used if the element is not eternal.
		Optional attribute. A value of 0 means that and Element can live for infinity.
		The default value is 0.
		
		diskPersistent:
		Whether the disk store persists between restarts of the Virtual Machine.
		The default value is false.
		
		diskExpiryThreadIntervalSeconds:
		The number of seconds between runs of the disk expiry thread. The default value
		is 120 seconds.
		
		diskSpoolBufferSizeMB:
		This is the size to allocate the DiskStore for a spool buffer. Writes are made
		to this area and then asynchronously written to disk. The default size is 30MB.
		Each spool buffer is used only by its cache. If you get OutOfMemory errors consider
		lowering this value. To improve DiskStore performance consider increasing it. Trace level
		logging in the DiskStore will show if put back ups are occurring.
		
		memoryStoreEvictionPolicy:
		Policy would be enforced upon reaching the maxElementsInMemory limit. Default
		policy is Least Recently Used (specified as LRU). Other policies available -
		First In First Out (specified as FIFO) and Less Frequently Used
		(specified as LFU)
		
		Cache elements can also contain sub elements which take the same format of a factory class
		and properties. Defined sub-elements are:
		
		* cacheEventListenerFactory - Enables registration of listeners for cache events, such as
		put, remove, update, and expire.
		
		* bootstrapCacheLoaderFactory - Specifies a BootstrapCacheLoader, which is called by a
		cache on initialization to pre-populate itself.
		
		* cacheExtensionFactory - Specifies a CacheExtension, a generic mechanism to tie a class
		which holds a reference to a cache to the cache lifecycle.
		
		* cacheExceptionHandlerFactory - Specifies a CacheExceptionHandler, which is called when
		cache exceptions occur.
		
		* cacheLoaderFactory - Specifies a CacheLoader, which can be used both asynchronously and
		synchronously to load objects into a cache.
		
		RMI Cache Replication
		
		Each cache that will be distributed needs to set a cache event listener which replicates
		messages to the other CacheManager peers. For the built-in RMI implementation this is done
		by adding a cacheEventListenerFactory element of type RMICacheReplicatorFactory to each
		distributed cache's configuration as per the following example:
		
		<cacheEventListenerFactory class="net.sf.ehcache.distribution.RMICacheReplicatorFactory"
		properties="replicateAsynchronously=true,
		replicatePuts=true,
		replicateUpdates=true,
		replicateUpdatesViaCopy=true,
		replicateRemovals=true
		asynchronousReplicationIntervalMillis=<number of milliseconds"
		propertySeparator="," />
		
		The RMICacheReplicatorFactory recognizes the following properties:
		
		* replicatePuts=true|false - whether new elements placed in a cache are
		replicated to others. Defaults to true.
		
		* replicateUpdates=true|false - whether new elements which override an
		element already existing with the same key are replicated. Defaults to true.
		
		* replicateRemovals=true - whether element removals are replicated. Defaults to true.
		
		* replicateAsynchronously=true | false - whether replications are
		asynchronous (true) or synchronous (false). Defaults to true.
		
		* replicateUpdatesViaCopy=true | false - whether the new elements are
		copied to other caches (true), or whether a remove message is sent. Defaults to true.
		
		* asynchronousReplicationIntervalMillis=<number of milliseconds> - The asynchronous
		replicator runs at a set interval of milliseconds. The default is 1000. The minimum
		is 10. This property is only applicable if replicateAsynchronously=true
		
		
		Cluster Bootstrapping
		
		The RMIBootstrapCacheLoader bootstraps caches in clusters where RMICacheReplicators are
		used. It is configured as per the following example:
		
		<bootstrapCacheLoaderFactory
		class="net.sf.ehcache.distribution.RMIBootstrapCacheLoaderFactory"
		properties="bootstrapAsynchronously=true, maximumChunkSizeBytes=5000000"
		propertySeparator="," />
		
		The RMIBootstrapCacheLoaderFactory recognizes the following optional properties:
		
		* bootstrapAsynchronously=true|false - whether the bootstrap happens in the background
		after the cache has started. If false, bootstrapping must complete before the cache is
		made available. The default value is true.
		
		* maximumChunkSizeBytes=<integer> - Caches can potentially be very large, larger than the
		memory limits of the VM. This property allows the bootstraper to fetched elements in
		chunks. The default chunk size is 5000000 (5MB).
		
		
		Cache Exception Handling
		
		By default, most cache operations will propagate a runtime CacheException on failure. An
		interceptor, using a dynamic proxy, may be configured so that a CacheExceptionHandler can
		be configured to intercept Exceptions. Errors are not intercepted.
		
		It is configured as per the following example:
		
		<cacheExceptionHandlerFactory class="com.example.ExampleExceptionHandlerFactory"
		properties="logLevel=FINE"/>
		
		Caches with ExceptionHandling configured are not of type Cache, but are of type Ehcache only,
		and are not available using CacheManager.getCache(), but using CacheManager.getEhcache().
		
		
		Cache Loader
		
		A default CacheLoader may be set which loads objects into the cache through asynchronous and
		synchronous methods on Cache. This is different to the bootstrap cache loader, which is used
		only in distributed caching.
		
		It is configured as per the following example:
		
		<cacheLoaderFactory class="com.example.ExampleCacheLoaderFactory"
		properties="type=int,startCounter=10"/>
		
		Cache Extension
		
		CacheExtensions are a general purpose mechanism to allow generic extensions to a Cache.
		CacheExtensions are tied into the Cache lifecycle.
		
		CacheExtensions are created using the CacheExtensionFactory which has a
		<code>createCacheCacheExtension()</code> method which takes as a parameter a
		Cache and properties. It can thus call back into any public method on Cache, including, of
		course, the load methods.
		
		Extensions are added as per the following example:
		
		<cacheExtensionFactory class="com.example.FileWatchingCacheRefresherExtensionFactory"
		properties="refreshIntervalMillis=18000, loaderTimeout=3000,
		flushPeriod=whatever, someOtherProperty=someValue ..."/>
		
	-->


	<!--
		Mandatory Default Cache configuration. These settings will be applied to caches
		created programmatically using CacheManager.add(String cacheName).
		
		The defaultCache has an implicit name "default" which is a reserved cache name.
		
		This cache contains a maximum in memory of 10000 elements, and will expire an element if it is idle for more than 24 hours.
		If there are more than 200 elements it will overflow to the disk cache.
		
		The disk store is persistent between cache and VM restarts. The disk expiry thread interval is set to 10
		minutes, overriding the default of 2 minutes.
		
		172800 sec = 48 hours
		86400 sec = 24 hours
		43200 sec = 12 hours		
		28800 sec = 8 hours
		14400 sec = 4 hours
		7200 sec = 2 hours
		3600 sec = 1 hour
		LRU = Least Recently Used
	-->
	<defaultCache maxElementsInMemory="200"
		eternal="false" overflowToDisk="false"
		timeToIdleSeconds="432000" timeToLiveSeconds="172800" diskPersistent="false"
		memoryStoreEvictionPolicy="LRU" />

	<!--
		Sparrow Bean caches. Initially all the same as the default cache...
	-->
	
	<!-- Distributed caches. Quoted from bottom of http://ehcache.org/documentation/distributed_caching.html
	
		Use of Time To Idle

			Time To Idle is inconsistent with distributed caching. Time-to-idle makes 
		some entries live longer on some nodes than in others because of cache 
		usage patterns. However, the cache entry "last touched" timestamp is 
		not replicated across the distributed cache.

			Do not use Time To Idle with distributed caching, unless you do not 
		care about inconsistent data across nodes. 
	 -->
	
	<!-- PredictionContext related caches -->
	<cache name="PredictContext" timeToIdleSeconds="14400" maxElementsInMemory="200"/>
	<cache name="AdjustmentGroups" timeToIdleSeconds="14400" maxElementsInMemory="200"/>
	<cache name="Analyses" timeToIdleSeconds="14400" maxElementsInMemory="200"/>
	<cache name="TerminalReaches" timeToIdleSeconds="14400" maxElementsInMemory="200"/>
	<cache name="AreaOfInterest" timeToIdleSeconds="14400" maxElementsInMemory="200"/>
    
    <cache name="PredefinedSessions" maxElementsInMemory="200"/>
		
	<cache name="ComparisonResult" maxElementsInMemory="5"
		timeToIdleSeconds="120" timeToLiveSeconds="240"/>
		
	<cache name="AnalysisResult" maxElementsInMemory="10" />
		
	<!-- Currently we cannot cache these, so 1 should turn off the cache. -->
	<cache name="NSDataSet" maxElementsInMemory="1"
		timeToIdleSeconds="60" timeToLiveSeconds="0"/>
		
	<!--
		Sparrow calculated value caches.
		These caches will all use the SelfPopulatingCache decorator, which
		extends BlockingCache.
		
		Each cache will have a CacheEntryFactory subclass associated with it that
		creates cache entries on demand.  The BlockingCache ensures that get requests
		that occur while the entry is being built are blocked until the factory
		completes.
		
		Calculation time is typically small (milliseconds), so the main purpose of
		these caches is to 'cushion' the impact of map tiles requests, which typically
		request 24 tiles at a time, and then batches of 4 as the user scrolls.
		
		None of these caches use disk storage.
	-->
	<cache name="PredictData" maxElementsInMemory="20" />
	
	<!--  This precursor to the DeliveryFraction is cached
	b/c it is used to filter rows as they are put into the
	NSDataSet for mapping.  Reaches not upstream of a target
	are given a special value. -->	
	<cache name="DeliveryFractionHash" maxElementsInMemory="4" />
	
	<!--  This is no reason to cache the delivery fraction
	since it is cached at the analysis level.
	NOTE: zero = unlimited size. -->
	<cache name="DeliveryFraction" maxElementsInMemory="1" />
		
	<cache name="AdjustedSource" maxElementsInMemory="10" />
	
	<cache name="PredictResult" maxElementsInMemory="10" />
	
	<cache name="IdentifyReachByPoint" maxElementsInMemory="10" />
	
	<cache name="IdentifyReachByID" maxElementsInMemory="100" />
		
	<cache name="LoadReachAttributes" maxElementsInMemory="20" />
		
	<cache name="ReachesByCriteria" maxElementsInMemory="3"/>
    
    <!--  Expesive to create and cheap to hold on to -->
    <cache name="DataBinning" maxElementsInMemory="200"/>
        
    <!-- Awesome kludge - temporary -->
    <cache name="AggregateIdLookup" maxElementsInMemory="4" />
	
	<cache name="StandardErrorEstimateData" maxElementsInMemory="10" />
		
	<cache name="LoadModelMetadata" maxElementsInMemory="20" />
		
	<cache name="CatchmentAreas" maxElementsInMemory="10" />
	
	<cache name="HUCTable" maxElementsInMemory="4" />
	
	<cache name="HUC" maxElementsInMemory="3" />
	
	<cache name="ReachWatershed" maxElementsInMemory="3" />
		
	<cache name="StreamFlow" maxElementsInMemory="10" />
	
	<cache name="EDACodeColumn" maxElementsInMemory="10" />
	<cache name="EDANameColumn" maxElementsInMemory="10" />
	

</ehcache>
